{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import PyPDF2\n",
    "import io\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_client = openai.Client(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draft_response(text):\n",
    "    # Create a chat completion to draft a response to the document\n",
    "    completion = openai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Draft a high-quality, clear, accurate, and helpful reply that answers all points raised in the correspondence, quotes any reference numbers and include the date the initial correspondence was sent. Address the response to the MP who sent the enquiry.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Draft a substantive reply for this correspondence:\\n\\n{text}\"}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def refine_response(original_text, style_preferences):\n",
    "    # OpenAI API call to refine the response based on user stylistic preferences\n",
    "    completion = openai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"Revise the following text according to the user's stylistic preferences: {style_preferences}.\"},\n",
    "            {\"role\": \"user\", \"content\": original_text}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    extracted_text = \"HI THERE BUDDY\"\n",
    "    st.session_state['extracted_text'] = extracted_text\n",
    "\n",
    "    print(\"Extracted text: \", extracted_text)\n",
    "\n",
    "    print(\"Yessir\")\n",
    "\n",
    "    response = draft_response(st.session_state['extracted_text'])\n",
    "    st.session_state['drafted_response'] = response\n",
    "    st.subheader(\"Drafted Response\")\n",
    "    st.write(response)\n",
    "\n",
    "    # User input for stylistic preferences\n",
    "    style_preferences = st.text_input(\"Input your stylistic preferences (e.g., formal, informal, use of specific terms):\")\n",
    "    \n",
    "    if st.button(\"Update Response\"):\n",
    "        if 'drafted_response' in st.session_state and style_preferences:\n",
    "            updated_response = refine_response(st.session_state['extracted_text'], style_preferences)\n",
    "            st.subheader(\"Updated Response\")\n",
    "            st.write(updated_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text:  HI THERE BUDDY\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
